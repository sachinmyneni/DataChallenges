{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train_ident = pd.read_csv('data/train_identity.csv.gz')\n",
    "df_train_transact = pd.read_csv('data/train_transaction.csv.gz')\n",
    "df_test_ident = pd.read_csv('data/test_identity.csv.gz')\n",
    "df_test_transact = pd.read_csv('data/test_transaction.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('df_train_ident.pickle','rb') as k:\n",
    "    df_train_ident = pickle.load(k)\n",
    "with open('df_train_transact.pickle','rb') as l:\n",
    "    df_train_transact = pickle.load(l)\n",
    "with open('df_test_ident.pickle','rb') as m:\n",
    "    df_test_ident = pickle.load(m)\n",
    "with open('df_test_transact.pickle','rb') as n:\n",
    "    df_test_transact = pickle.load(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TransactionID as index for both data.\n",
    "df_train_ident.set_index('TransactionID',inplace=True)\n",
    "df_train_transact.set_index('TransactionID',inplace=True)\n",
    "df_test_ident.set_index('TransactionID',inplace=True)\n",
    "df_test_transact.set_index('TransactionID',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train = pd.merge(df_train_transact, df_train_ident, on='TransactionID', how='left')\n",
    "df_test = pd.merge(df_test_transact, df_test_ident, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_test_leftMerged.pickle','rb') as f:\n",
    "    df_test = pickle.load(f)\n",
    "with open('df_train_leftMerged.pickle','rb') as g:\n",
    "    df_train = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = str(line).lower()\n",
    "    line = re.sub(r\"[^\\w\\s]\", '_', line)\n",
    "    line = re.sub(r\"\\s+\", ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert TransactionDT to a weekday number.\n",
    "df_train['WD'] = pd.to_timedelta(df_train['TransactionDT'],unit='seconds')+np.datetime64('2015-01-01')\n",
    "df_test['WD']  = pd.to_timedelta(df_test['TransactionDT'],unit='seconds')+np.datetime64('2015-01-01')\n",
    "df_train['WD'] = df_train['WD'].dt.dayofweek\n",
    "df_test['WD'] = df_test['WD'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break up resolution string of format num1 x num2 into 2 columns (num1 and num2)\n",
    "# each being an int.\n",
    "df_train['res1'] = df_train[~pd.isnull(df_train['id_33'])]['id_33'].apply(lambda x: str(x).split('x')[0])\n",
    "df_train['res2'] = df_train[~pd.isnull(df_train['id_33'])]['id_33'].apply(lambda x: str(x).split('x')[1])\n",
    "df_test['res1'] = df_test[~pd.isnull(df_test['id_33'])]['id_33'].apply(lambda x: str(x).split('x')[0])\n",
    "df_test['res2'] = df_test[~pd.isnull(df_test['id_33'])]['id_33'].apply(lambda x: str(x).split('x')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all columns which have more than 25% as no-values/NaN\n",
    "miss_val_threshold = 0.25\n",
    "\n",
    "col_to_del = []\n",
    "\n",
    "for c in df_train.columns:\n",
    "    if df_train[c].isnull().sum() > df_train.shape[0]*miss_val_threshold:\n",
    "        col_to_del.append(c)\n",
    "\n",
    "for c in df_test.columns:\n",
    "    if df_train[c].isnull().sum() > df_test.shape[0]*miss_val_threshold:\n",
    "        if c not in col_to_del:\n",
    "            col_to_del.append(c)\n",
    "        \n",
    "col_to_del.append('TransactionID')\n",
    "col_to_del.append('TransactionDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_transactionids = df_test['TransactionID']\n",
    "df_train.drop(columns=col_to_del, inplace = True)\n",
    "df_test.drop(columns=col_to_del, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.fillna(-999, inplace= True)\n",
    "df_test.fillna(-999, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 590540 entries, 0 to 590539\n",
      "Columns: 181 entries, isFraud to WD\n",
      "dtypes: float64(174), int64(3), object(4)\n",
      "memory usage: 820.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 506691 entries, 0 to 506690\n",
      "Columns: 180 entries, TransactionAmt to WD\n",
      "dtypes: float64(174), int64(2), object(4)\n",
      "memory usage: 699.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# before optimization\n",
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_int16 = ['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2',\n",
    "           'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14',\n",
    "           'D1', 'D10', 'D15', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
    "           'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
    "           'V31', 'V32', 'V33', 'V34', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59',\n",
    "           'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', \n",
    "           'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79',\n",
    "           'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89',\n",
    "           'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99',\n",
    "           'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109',\n",
    "           'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119',\n",
    "           'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129',\n",
    "           'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V279',\n",
    "           'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289',\n",
    "           'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299',\n",
    "           'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309',\n",
    "           'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319',\n",
    "           'V320', 'V321']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in col_int16:\n",
    "    df_train[c] = df_train[c].astype(np.int16)\n",
    "    df_test[c] = df_test[c].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding of categorical values in train dataset\n",
    "col_dummies = ['ProductCD', 'card4', 'card6', 'P_emaildomain']\n",
    "\n",
    "for c in col_dummies:\n",
    "    df_train[c] = pd.get_dummies(df_train[c])\n",
    "    df_test[c] = pd.get_dummies(df_test[c])\n",
    "    \n",
    "# drop one-hot-encoded features     \n",
    "df_train.drop(columns=col_dummies, inplace = True)  \n",
    "df_test.drop(columns=col_dummies, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 590540 entries, 0 to 590539\n",
      "Columns: 177 entries, isFraud to WD\n",
      "dtypes: float64(1), int16(174), int64(2)\n",
      "memory usage: 214.0 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 506691 entries, 0 to 506690\n",
      "Columns: 176 entries, TransactionAmt to WD\n",
      "dtypes: float64(1), int16(174), int64(1)\n",
      "memory usage: 179.8 MB\n"
     ]
    }
   ],
   "source": [
    "# after optimization\n",
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# free memory\n",
    "del df_train_ident, df_train_transact, df_test_ident, df_test_transact\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData():\n",
    "    df_train_neg = df_train.loc[df_train['isFraud'] == 0]\n",
    "    df_train_pos = df_train.loc[df_train['isFraud'] == 1]\n",
    "    \n",
    "    split = 0.2\n",
    "    x_train_pos, x_val_pos = train_test_split(df_train_pos, test_size=split, random_state=42)\n",
    "    x_train_neg, x_val_neg = train_test_split(df_train_neg, test_size=split, random_state=42)\n",
    "    \n",
    "    #downsample the majority to achieve 1:1 class distribution\n",
    "    x_train_neg = x_train_neg.sample(frac=1/27)\n",
    "    x_val_neg   = x_val_neg.sample(frac=1/27)\n",
    "    \n",
    "    #combine and reshuffle training and validation sets\n",
    "    x_train = (x_train_pos.append(x_train_neg)).sample(frac=1)\n",
    "    x_val   = (x_val_pos.append(x_val_neg)).sample(frac=1)\n",
    "    \n",
    "    y_train = x_train.pop('isFraud')\n",
    "    y_val   = x_val.pop('isFraud')\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('isFraud',axis=1)\n",
    "y = df_train['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.59969729\n",
      "Iteration 2, loss = 0.58332264\n",
      "Iteration 3, loss = 0.57461549\n",
      "Iteration 4, loss = 0.57977562\n",
      "Iteration 5, loss = 0.57705239\n",
      "Iteration 6, loss = 0.57193922\n",
      "Iteration 7, loss = 0.57104544\n",
      "Iteration 8, loss = 0.57035794\n",
      "Iteration 9, loss = 0.56943975\n",
      "Iteration 10, loss = 0.56928467\n",
      "Iteration 11, loss = 0.57208773\n",
      "Iteration 12, loss = 0.56949497\n",
      "Iteration 13, loss = 0.56942041\n",
      "Iteration 14, loss = 0.57180322\n",
      "Iteration 15, loss = 0.56718959\n",
      "Iteration 16, loss = 0.56600183\n",
      "Iteration 17, loss = 0.56811865\n",
      "Iteration 18, loss = 0.56487589\n",
      "Iteration 19, loss = 0.56500207\n",
      "Iteration 20, loss = 0.56524559\n",
      "Iteration 21, loss = 0.56657645\n",
      "Iteration 22, loss = 0.56495430\n",
      "Iteration 23, loss = 0.56650653\n",
      "Iteration 24, loss = 0.56516263\n",
      "Iteration 25, loss = 0.56832950\n",
      "Iteration 26, loss = 0.56587203\n",
      "Iteration 27, loss = 0.56492048\n",
      "Iteration 28, loss = 0.56405061\n",
      "Iteration 29, loss = 0.56185235\n",
      "Iteration 30, loss = 0.56157801\n",
      "Iteration 31, loss = 0.56327861\n",
      "Iteration 32, loss = 0.56169770\n",
      "Iteration 33, loss = 0.55999900\n",
      "Iteration 34, loss = 0.55971876\n",
      "Iteration 35, loss = 0.56059920\n",
      "Iteration 36, loss = 0.55939263\n",
      "Iteration 37, loss = 0.56199276\n",
      "Iteration 38, loss = 0.56381472\n",
      "Iteration 39, loss = 0.56091576\n",
      "Iteration 40, loss = 0.56598119\n",
      "Iteration 41, loss = 0.56333140\n",
      "Iteration 42, loss = 0.56240739\n",
      "Iteration 43, loss = 0.56039500\n",
      "Iteration 44, loss = 0.55683340\n",
      "Iteration 45, loss = 0.55724904\n",
      "Iteration 46, loss = 0.55849244\n",
      "Iteration 47, loss = 0.55908159\n",
      "Iteration 48, loss = 0.56049982\n",
      "Iteration 49, loss = 0.56279822\n",
      "Iteration 50, loss = 0.56246241\n",
      "Iteration 51, loss = 0.56266479\n",
      "Iteration 52, loss = 0.56200401\n",
      "Iteration 53, loss = 0.55626142\n",
      "Iteration 54, loss = 0.55805392\n",
      "Iteration 55, loss = 0.56380748\n",
      "Iteration 56, loss = 0.55852880\n",
      "Iteration 57, loss = 0.56164908\n",
      "Iteration 58, loss = 0.56487509\n",
      "Iteration 59, loss = 0.56210563\n",
      "Iteration 60, loss = 0.56470735\n",
      "Iteration 61, loss = 0.55983523\n",
      "Iteration 62, loss = 0.56432214\n",
      "Iteration 63, loss = 0.56140987\n",
      "Iteration 64, loss = 0.55777447\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "X_train, X_test, y_train, y_test = splitData()\n",
    "\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(300,),activation='tanh',alpha=0.01,max_iter=1000,verbose=True)\n",
    "# T R A I N\n",
    "# Fit the classifier to the training data\n",
    "mlpc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2832 1389]\n",
      " [ 935 3198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      4221\n",
      "           1       0.70      0.77      0.73      4133\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      8354\n",
      "   macro avg       0.72      0.72      0.72      8354\n",
      "weighted avg       0.72      0.72      0.72      8354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# P R E D I C T\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = mlpc.predict(X_test)\n",
    "\n",
    "#\n",
    "# E V A L U A T E\n",
    "#\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# R O C \n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = mlpc.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7905777187134735\n",
      "Iteration 1, loss = 0.13858769\n",
      "Iteration 2, loss = 0.13509946\n",
      "Iteration 3, loss = 0.13528833\n",
      "Iteration 4, loss = 0.13532357\n",
      "Iteration 5, loss = 0.13544382\n",
      "Iteration 6, loss = 0.13501430\n",
      "Iteration 7, loss = 0.13495088\n",
      "Iteration 8, loss = 0.13438226\n",
      "Iteration 9, loss = 0.13636596\n",
      "Iteration 10, loss = 0.13485867\n",
      "Iteration 11, loss = 0.13478867\n",
      "Iteration 12, loss = 0.13504298\n",
      "Iteration 13, loss = 0.13601829\n",
      "Iteration 14, loss = 0.13582021\n",
      "Iteration 15, loss = 0.13529313\n",
      "Iteration 16, loss = 0.13627045\n",
      "Iteration 17, loss = 0.13556579\n",
      "Iteration 18, loss = 0.13537787\n",
      "Iteration 19, loss = 0.13493287\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.14405696\n",
      "Iteration 2, loss = 0.13907775\n",
      "Iteration 3, loss = 0.13888350\n",
      "Iteration 4, loss = 0.13789163\n",
      "Iteration 5, loss = 0.13834621\n",
      "Iteration 6, loss = 0.13844600\n",
      "Iteration 7, loss = 0.13792381\n",
      "Iteration 8, loss = 0.13785452\n",
      "Iteration 9, loss = 0.13830989\n",
      "Iteration 10, loss = 0.13774867\n",
      "Iteration 11, loss = 0.13810897\n",
      "Iteration 12, loss = 0.13747606\n",
      "Iteration 13, loss = 0.13786235\n",
      "Iteration 14, loss = 0.13761736\n",
      "Iteration 15, loss = 0.13760720\n",
      "Iteration 16, loss = 0.13865746\n",
      "Iteration 17, loss = 0.13779958\n",
      "Iteration 18, loss = 0.13926896\n",
      "Iteration 19, loss = 0.13831877\n",
      "Iteration 20, loss = 0.13844861\n",
      "Iteration 21, loss = 0.13825494\n",
      "Iteration 22, loss = 0.13766537\n",
      "Iteration 23, loss = 0.13803800\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.14086792\n",
      "Iteration 2, loss = 0.13967923\n",
      "Iteration 3, loss = 0.13840647\n",
      "Iteration 4, loss = 0.13806077\n",
      "Iteration 5, loss = 0.13711926\n",
      "Iteration 6, loss = 0.13749289\n",
      "Iteration 7, loss = 0.13723215\n",
      "Iteration 8, loss = 0.13686644\n",
      "Iteration 9, loss = 0.13671677\n",
      "Iteration 10, loss = 0.13790377\n",
      "Iteration 11, loss = 0.13790636\n",
      "Iteration 12, loss = 0.13730450\n",
      "Iteration 13, loss = 0.13661718\n",
      "Iteration 14, loss = 0.13569423\n",
      "Iteration 15, loss = 0.13564416\n",
      "Iteration 16, loss = 0.13591147\n",
      "Iteration 17, loss = 0.13786311\n",
      "Iteration 18, loss = 0.13714095\n",
      "Iteration 19, loss = 0.13629813\n",
      "Iteration 20, loss = 0.13673122\n",
      "Iteration 21, loss = 0.13565603\n",
      "Iteration 22, loss = 0.13443044\n",
      "Iteration 23, loss = 0.13443704\n",
      "Iteration 24, loss = 0.13634176\n",
      "Iteration 25, loss = 0.13617770\n",
      "Iteration 26, loss = 0.13624074\n",
      "Iteration 27, loss = 0.13787511\n",
      "Iteration 28, loss = 0.13747055\n",
      "Iteration 29, loss = 0.13645309\n",
      "Iteration 30, loss = 0.13688061\n",
      "Iteration 31, loss = 0.13570140\n",
      "Iteration 32, loss = 0.13499545\n",
      "Iteration 33, loss = 0.13646331\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.14362214\n",
      "Iteration 2, loss = 0.14010276\n",
      "Iteration 3, loss = 0.13917785\n",
      "Iteration 4, loss = 0.13882955\n",
      "Iteration 5, loss = 0.13923456\n",
      "Iteration 6, loss = 0.13907291\n",
      "Iteration 7, loss = 0.13849445\n",
      "Iteration 8, loss = 0.13854232\n",
      "Iteration 9, loss = 0.13911518\n",
      "Iteration 10, loss = 0.13887846\n",
      "Iteration 11, loss = 0.13848787\n",
      "Iteration 12, loss = 0.13838956\n",
      "Iteration 13, loss = 0.13797330\n",
      "Iteration 14, loss = 0.13817758\n",
      "Iteration 15, loss = 0.13805410\n",
      "Iteration 16, loss = 0.13839476\n",
      "Iteration 17, loss = 0.13755246\n",
      "Iteration 18, loss = 0.13849646\n",
      "Iteration 19, loss = 0.13845455\n",
      "Iteration 20, loss = 0.13833541\n",
      "Iteration 21, loss = 0.13778580\n",
      "Iteration 22, loss = 0.13851735\n",
      "Iteration 23, loss = 0.13787597\n",
      "Iteration 24, loss = 0.13838083\n",
      "Iteration 25, loss = 0.13714841\n",
      "Iteration 26, loss = 0.13903550\n",
      "Iteration 27, loss = 0.13908552\n",
      "Iteration 28, loss = 0.13845858\n",
      "Iteration 29, loss = 0.13811022\n",
      "Iteration 30, loss = 0.13843158\n",
      "Iteration 31, loss = 0.13761691\n",
      "Iteration 32, loss = 0.13709263\n",
      "Iteration 33, loss = 0.13793524\n",
      "Iteration 34, loss = 0.13740464\n",
      "Iteration 35, loss = 0.13699199\n",
      "Iteration 36, loss = 0.13661435\n",
      "Iteration 37, loss = 0.13747417\n",
      "Iteration 38, loss = 0.13808063\n",
      "Iteration 39, loss = 0.13827290\n",
      "Iteration 40, loss = 0.13757968\n",
      "Iteration 41, loss = 0.13802021\n",
      "Iteration 42, loss = 0.13726147\n",
      "Iteration 43, loss = 0.13675192\n",
      "Iteration 44, loss = 0.13703319\n",
      "Iteration 45, loss = 0.13689845\n",
      "Iteration 46, loss = 0.13702107\n",
      "Iteration 47, loss = 0.13796563\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.14266254\n",
      "Iteration 2, loss = 0.13885210\n",
      "Iteration 3, loss = 0.13879399\n",
      "Iteration 4, loss = 0.13895866\n",
      "Iteration 5, loss = 0.13843413\n",
      "Iteration 6, loss = 0.13836958\n",
      "Iteration 7, loss = 0.13897991\n",
      "Iteration 8, loss = 0.13849365\n",
      "Iteration 9, loss = 0.13757527\n",
      "Iteration 10, loss = 0.13694736\n",
      "Iteration 11, loss = 0.13559491\n",
      "Iteration 12, loss = 0.13591209\n",
      "Iteration 13, loss = 0.13696051\n",
      "Iteration 14, loss = 0.13778936\n",
      "Iteration 15, loss = 0.13808551\n",
      "Iteration 16, loss = 0.13854800\n",
      "Iteration 17, loss = 0.13838580\n",
      "Iteration 18, loss = 0.13834210\n",
      "Iteration 19, loss = 0.13822593\n",
      "Iteration 20, loss = 0.13781512\n",
      "Iteration 21, loss = 0.13764758\n",
      "Iteration 22, loss = 0.13697079\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "AUC scores computed using 5-fold cross-validation: [0.68760272 0.77994673 0.76763299 0.78537751 0.77148591]\n"
     ]
    }
   ],
   "source": [
    "# A U C\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = mlpc.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(mlpc,X,y,scoring='roc_auc',cv=5)\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real_pred = mlpc.predict_proba(df_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict(zip(df_test_transactionids.to_list(),y_real_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = results_dict.items()\n",
    "results_df = pd.DataFrame({'TransactionID': [i[0] for i in items], 'isFraud': [i[1] for i in items]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results_mlcp.csv',index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rank : Score\n",
    "2059 : 0.8490\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
